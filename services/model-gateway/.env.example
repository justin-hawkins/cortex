# File: services/model-gateway/.env.example
# Environment variables for model-gateway service
# Copy this to .env and fill in your values

# =============================================================================
# Provider Endpoints (from servers.yaml)
# =============================================================================

# Ollama CPU server (AMD Epyc with RTX 5060 Ti)
OLLAMA_CPU_ENDPOINT=http://192.168.1.11:11434

# Ollama GPU server (RTX 4060 Ti)
OLLAMA_GPU_ENDPOINT=http://192.168.1.12:11434

# vLLM server (OpenAI-compatible API)
VLLM_ENDPOINT=http://192.168.1.11:8000/v1

# =============================================================================
# API Keys (Required for external providers)
# =============================================================================

# Anthropic API key for Claude models
ANTHROPIC_API_KEY=sk-ant-your-key-here

# =============================================================================
# Service Configuration
# =============================================================================

# Service port
SERVICE_PORT=8000

# Log level (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# =============================================================================
# Observability (OpenTelemetry)
# =============================================================================

# OTEL service name
OTEL_SERVICE_NAME=model-gateway

# OTEL exporter endpoint (Jaeger, etc.)
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# =============================================================================
# Rate Limiting (Future - Redis required)
# =============================================================================

# Redis URL for rate limiting (not yet implemented)
# REDIS_URL=redis://192.168.1.44:6379/0
# RATE_LIMIT_ENABLED=false